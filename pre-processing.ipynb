{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look for loan biases in this housing data we must import and clean the data set so that we can perform analyses\n",
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import hashlib\n",
    "from functools import reduce\n",
    "\n",
    "# Get the total number of rows in the data set prior to filtering out bad, missing, or corrupt lines\n",
    "# use the number to compare the size of the data set after filtering \n",
    "columnNames = []\n",
    "with open('headers.txt', 'r') as headerFile:\n",
    "    headerReader = csv.reader(headerFile, delimiter=',')\n",
    "    for row in headerReader:\n",
    "        columnNames.append(row[1])\n",
    "        \n",
    "numCols = len(columnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: 0 Missing: 0   Kept: 439655   Total: 439655\n"
     ]
    }
   ],
   "source": [
    "invalidCols = 0; duplicateRows = 0; keptRows = 0; missingCols = 0; totalRows = 0\n",
    "onHeader = True\n",
    "rows = set()\n",
    "with open('hmda_lar.csv', 'r') as dataFile:\n",
    "    with open('valid_rows_sample_small.csv', 'w') as outFile:\n",
    "        dataReader = csv.reader(dataFile, delimiter=',')\n",
    "        outWriter = csv.writer(outFile, delimiter = ',')\n",
    "        for row in dataReader:\n",
    "            # Skip the header line\n",
    "            totalRows += 1\n",
    "            # Ignore rows with incorrect number of columns\n",
    "            if len(row) != numCols:\n",
    "                invalidCols += 1\n",
    "                continue \n",
    "            else:\n",
    "                # Ignore rows where more than 1/2 of the entries are missing\n",
    "                # Count the number of nan's in a row\n",
    "                missingFields = reduce(lambda x, y: x + int(y == \"\"), row, 0) # do not change \"\" to ''\n",
    "                if missingFields >= int(0.5 * numCols):\n",
    "                    missingCols += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    keptRows += 1\n",
    "                    outWriter.writerow(row)\n",
    "print(\"Dropped: %d Missing: %d   Kept: %d   Total: %d\" % (invalidCols, missingCols,\n",
    "                                                                             keptRows, totalRows))\n",
    "\n",
    "# If we only drop duplicates that match on all fields these are the results.   \n",
    "# Dropped:     Duplicates:     De-duplicated:     Total:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup = pd.read_csv(\"valid_rows_sample_small.csv\", sep=',', engine='python', error_bad_lines=False, dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "df_dedup = df.drop_duplicates(keep='first');\n",
    "duplicateRows = df_dup.shape[0]- df_dedup.shape[0]\n",
    "print(\"Duplicates: %d\" % duplicateRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guarantees all rows are accounted for after filtering data\n",
    "invalidCols + duplicateRows + missingCols + keptRows == totalRows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following object contains suggested data types for the corresponding columns. The column headers not in this object are best represented as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "colToType = {\n",
    "    \"tract_to_msamd_income\" : float, \n",
    "    \"rate_spread\" : float,\n",
    "    \"population\" : int,\n",
    "    \"minority_population\" : bool,\n",
    "    \"number_of_owner_occupied_units\" : int, \n",
    "    \"number_of_1_to_4_family_units\" : int, \n",
    "    \"loan_amount_000s\" : float, \n",
    "    \"hud_median_family_income\" : float,\n",
    "    \"applicant_income_000s\" : float,\n",
    "    \"sequence_number\" : int, \n",
    "    \"census_tract_number\" : float, \n",
    "    \"as_of_year\" : int,\n",
    "    \"application_date_indicator\" : int,     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToBool(x):\n",
    "    if x == 'True': return True\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplicated Valid Rows: 439654\tFully Deduplicated: True\n",
      "Columns: 47\n"
     ]
    }
   ],
   "source": [
    "df_test = df_dedup\n",
    "# Use Pandas drop_duplicates() as evidence that dataset is deduplicated\n",
    "print(\"Deduplicated Valid Rows: %d\\tFully Deduplicated: %r\" \n",
    "      % (len(df_test), len(df_test) == len(df_test.drop_duplicates())))\n",
    "print(\"Columns: %d\" % len(df_test.columns.values))\n",
    "\n",
    "# Convert types of columns\n",
    "for colName, colType in colToType.items():\n",
    "    if colType == int:\n",
    "        df_test[colName] = df_test[colName].apply(lambda x: x if x != 'nan' else 0).astype(int)\n",
    "    if colType == float:\n",
    "        df_test[colName] = df_test[colstate_nameName].apply(lambda x: x if x != 'nan' else float('nan')).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some fields may have values that are incompatible types. This may occur when no data is stored for a variable, a user did not complete the course or course registration, or a column may contain multiple data types. A string representation of an age cannot be compared to a number. If a user inputted N/A, or left that field blank, it is interpreted differently as NA, na, NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.replace(\"nan\", np.nan, inplace=True)\n",
    "df_test.replace(\"None\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this data set is specific to New York State so there is no need to keep the state name and abbrevation NY\n",
    "df_test.drop([\"state_name\",\"state_abbr\"],axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
