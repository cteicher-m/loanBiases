{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will utilize our pre-processed and cleaned data set in order to answer our research question: \n",
    "### Is lending racially discriminatory in the New York State?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression as OLS\n",
    "from sklearn.linear_model import LogisticRegression as Logit\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.formula.api as sm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv from pre-processing. We must re-cast types because they were converted to strings upon exporting. \n",
    "df = pd.read_csv(\"encoded_loan_data.csv\", sep=',', engine='python', error_bad_lines=False, dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(df.applicant_race_name_1.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define immutable, related set of constant values.\n",
    "import enum\n",
    "from functools import total_ordering\n",
    "@total_ordering\n",
    "class Race(enum.Enum):\n",
    "    Native = 'American Indian or Alaska Native'\n",
    "    Asian = 'Asian'\n",
    "    Black = 'Black or African American'\n",
    "    PacificIslander = 'Native Hawaiian or Other Pacific Islander'\n",
    "    White = 'White'\n",
    "    nan = 'nan'\n",
    "    def __lt__(self, other):\n",
    "        if self.__class__ is other.__class__:\n",
    "            return self.value < other.value\n",
    "        return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before visualizing this data we must ensure all processed data is numeric. These column types match those discussed in pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colToType = {\n",
    "    \"tract_to_msamd_income\" : float, \n",
    "    \"rate_spread\" : float,\n",
    "    \"population\" : int,\n",
    "    \"minority_population\" : bool,\n",
    "    \"number_of_owner_occupied_units\" : int, \n",
    "    \"number_of_1_to_4_family_units\" : int, \n",
    "    \"loan_amount_000s\" : float, \n",
    "    \"hud_median_family_income\" : float,\n",
    "    \"applicant_income_000s\" : float,\n",
    "    \"sequence_number\" : int, \n",
    "    \"census_tract_number\" : float, \n",
    "    \"as_of_year\" : int,\n",
    "    \"application_date_indicator\" : int, \n",
    "    \"applicant_race_name_1\": Race,\n",
    "    \"applicant_race_name_2\": Race,\n",
    "    \"applicant_race_name_3\": Race,\n",
    "    \"applicant_race_name_4\": Race,\n",
    "    \"applicant_race_name_5\": Race,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert aforementioned column types\n",
    "df_test = df\n",
    "# Use Pandas drop_duplicates() as evidence that dataset is deduplicated\n",
    "print(\"Deduplicated Valid Rows: %d\\tFully Deduplicated: %r\" \n",
    "      % (len(df_test), len(df_test) == len(df_test.drop_duplicates())))\n",
    "print(\"Columns: %d\" % len(df_test.columns.values))\n",
    "\n",
    "# Convert types of columns\n",
    "for colName, colType in colToType.items():\n",
    "    if colType == int:\n",
    "        df_test[colName] = df_test[colName].apply(lambda x: x if x != 'nan' else 0).astype(int)\n",
    "    elif colType == float:\n",
    "        df_test[colName] = df_test[colName].apply(lambda x: x if x != 'nan' else float('nan')).astype(float)\n",
    "    elif colType == Race:\n",
    "        df_test[colName] = df_test[colName].apply(lambda x: Race(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column types were correctly converted\n",
    "assert [col in ['int64','float'] for col in [df[y].dtype for y in numeric_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.applicant_race_name_1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the samples for Native Americans and Pacific Islanders are so small, we will exclude them for much of the analysis that is testing the effects of race on mortgage approval status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name each income bucket in order to plot data \n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(0, 18]', 1)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(18, 75]', 2)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(75, 153]', 3)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(153, 233]', 4)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(233, 416]', 5)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(416, 470]', 6)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(470, 9999]', 7)\n",
    "# Applicants with no income reported will be meaningless in our analysis and will be indicated in the -1 column.\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('nan', -1)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].astype('float')\n",
    "df[\"action_taken_name\"] = df[\"action_taken_name\"].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data frames to run analyses on gender disaggregated data\n",
    "df_gender_male = df.copy()\n",
    "df_gender_female = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant income histogram\n",
    "df.income_bracket.hist(bins = range(-1,8))\n",
    "plt.title('Applicant Income')\n",
    "plt.xlabel('All Applicant Incomes')\n",
    "plt.ylabel('Number of applicants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all female data\n",
    "df_gender_male = df_gender_male.drop(df_gender_male[df_gender_male.applicant_sex_name == \"Female\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all male data \n",
    "df_gender_female = df_gender_female.drop(df_gender_female[df_gender_female.applicant_sex_name == \"Male\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applicant income for male histogram\n",
    "df_gender_male.income_bracket.hist(bins = range(-1,8))\n",
    "plt.title('Male Applicant Income')\n",
    "plt.xlabel('All male applicant incomes')\n",
    "plt.ylabel('Number of applicants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applicant income for women histogram\n",
    "df_gender_female.income_bracket.hist(bins = range(-1,8))\n",
    "plt.title('Female Applicant Income')\n",
    "plt.xlabel('All Female applicant incomes')\n",
    "plt.ylabel('Number of applicants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Graph loan frequency of originated loan/purchased by institution for each income bracket\n",
    "# disaggregated by race  \n",
    "fig = plt.figure()\n",
    "ax = df[(df.applicant_race_name_1 != Race.nan)]\\\n",
    ".groupby([\"applicant_race_name_1\", \"income_bracket\"])\\\n",
    ".action_taken_name.mean()\\\n",
    ".reset_index().set_index([\"income_bracket\", \"applicant_race_name_1\"])\\\n",
    ".unstack(\"applicant_race_name_1\")\\\n",
    ".rename_axis([None, \"applicant_race_name_1\"], axis = 1).plot.bar(color = 'ygkrb')\n",
    "\n",
    "plt.title('Loan status by income, conditional on race')\n",
    "plt.xlabel('Income Bracket')\n",
    "plt.ylabel('Loan Origination Status')\n",
    "ax.legend(['Native American', 'Asian', 'Black or African American'\n",
    "           ,'Pacific Islander','White'], bbox_to_anchor=(1.1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph loan frequency of originated loan/purchased by institution for each income bracket\n",
    "# disaggregated by race only for Asian, Black, and White\n",
    "fig = plt.figure()\n",
    "ax = df[~(df.applicant_race_name_1.isin([Race.nan, Race.Native, Race.PacificIslander]))]\\\n",
    ".groupby([\"applicant_race_name_1\", \"income_bracket\"])\\\n",
    ".action_taken_name.mean()\\\n",
    ".reset_index().set_index([\"income_bracket\", \"applicant_race_name_1\"])\\\n",
    ".unstack(\"applicant_race_name_1\")\\\n",
    ".rename_axis([None, \"applicant_race_name_1\"], axis = 1).plot.bar(color = 'gkb')\n",
    "\n",
    "plt.title('Loan status by income, conditional on race')\n",
    "plt.xlabel('Income Bracket')\n",
    "plt.ylabel('Loan Origination Status')\n",
    "ax.legend(['Asian', 'Black or African American', 'White'], bbox_to_anchor=(1.1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance between asian and white, black and white, frequencies of originated loans/purchased by institution \n",
    "whiteMeans = df[(df.applicant_race_name_1 == Race.White) & (df.income_bracket > 0)].groupby([\"applicant_race_name_1\", \"income_bracket\"])\\\n",
    ".action_taken_name.mean().reset_index().set_index(\"income_bracket\").drop(\"applicant_race_name_1\", axis = 1)\n",
    "\n",
    "asianMeans = df[(df.applicant_race_name_1 == Race.Asian) & (df.income_bracket > 0)].groupby([\"applicant_race_name_1\", \"income_bracket\"])\\\n",
    ".action_taken_name.mean().reset_index().set_index(\"income_bracket\").drop(\"applicant_race_name_1\", axis = 1)\n",
    "\n",
    "blackMeans = df[(df.applicant_race_name_1 == Race.Black) & (df.income_bracket > 0)].groupby([\"applicant_race_name_1\", \"income_bracket\"])\\\n",
    ".action_taken_name.mean().reset_index().set_index(\"income_bracket\").drop(\"applicant_race_name_1\", axis = 1)\n",
    "\n",
    "asianDiffRelWhites = (asianMeans - whiteMeans).mean()\n",
    "blackDiffRelWhites = (blackMeans - whiteMeans).mean()\n",
    "\n",
    "print(\"After controlling for income, asians were %0.2f%% less likely to get a loan approved relative to whites.\" % \n",
    "      (asianDiffRelWhites * 100))\n",
    "print(\"After controlling for income, blacks were %0.2f%% less likely to get a loan approved relative to whites.\" %\n",
    "      (blackDiffRelWhites * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same graph but exclusively for primary male applicants\n",
    "fig = plt.figure()\n",
    "ax = df[df.applicant_race_name_1.isin([Race.Asian, Race.Black, Race.White])]\\\n",
    ".groupby([\"applicant_race_name_1\", \"income_bracket\"]).action_taken_name\\\n",
    ".mean()\\\n",
    ".reset_index().set_index([\"income_bracket\", \"applicant_race_name_1\"])\\\n",
    ".unstack(\"applicant_race_name_1\")\\\n",
    ".plot.bar(color = 'gkb')\n",
    "\n",
    "ax.legend([\"Asian\", \"Black or African American\", \"White\"], bbox_to_anchor=(1.1, 1.0))\n",
    "plt.title('Loan status by income, conditional on race for Male Applicants')\n",
    "plt.xlabel('Income Bracket')\n",
    "plt.ylabel('Loan status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same graph but exclusively for primary female applicants\n",
    "fig = plt.figure()\n",
    "ax = df_gender_female[df_gender_female.applicant_race_name_1.isin([Race.Asian, Race.Black, Race.White])]\\\n",
    ".groupby([\"applicant_race_name_1\", \"income_bracket\"]).action_taken_name\\\n",
    ".mean()\\\n",
    ".reset_index().set_index([\"income_bracket\", \"applicant_race_name_1\"])\\\n",
    ".unstack(\"applicant_race_name_1\")\\\n",
    ".plot.bar(color = 'gkb')\n",
    "\n",
    "plt.title('Loan status by income, conditional on race for Female Applicants')\n",
    "plt.xlabel('Income Bracket')\n",
    "plt.ylabel('Loan status')\n",
    "ax.legend(['Asian', 'Black or African American','White'], bbox_to_anchor=(1.1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the mean number of application results for each race, we see for any income bracket, aside from one of the higher income brackets, there is a consistent discrepancy between loan status and race. Black or African American applicants were denied loan applications more frequently than white applicants. The amount by which the number of applicants with originated loans differ, is inconsistent between different races and across different income brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of Native Hawaiian or Other Pacific Islander and American Indian applicants is low. As a result the confidence intervals for the following plot will be too large in order to gauage meaningful analyses with regards to race and application status?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loan status proportions and counts by applicant race and income bracket.\n",
    "p_afram = df[df.applicant_race_name_1== Race.Black].groupby('income_bracket').action_taken_name.mean()\n",
    "n_afram = df[df.applicant_race_name_1== Race.Black].groupby('income_bracket').action_taken_name.count()\n",
    "\n",
    "p_white = df[df.applicant_race_name_1== Race.White].groupby('income_bracket').action_taken_name.mean()\n",
    "n_white = df[df.applicant_race_name_1== Race.White].groupby('income_bracket').action_taken_name.count()\n",
    "\n",
    "p_asian = df[df.applicant_race_name_1== Race.Asian].groupby('income_bracket').action_taken_name.mean()\n",
    "n_asian = df[df.applicant_race_name_1== Race.Asian].groupby('income_bracket').action_taken_name.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the proportions with 1-SD error bars\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "x = np.array([-1] + list(range(1,8)))\n",
    "\n",
    "sd_asian = 1.96*np.sqrt(p_asian*(1-p_asian)/n_asian)\n",
    "plt.vlines(x+.2, p_asian+sd_asian, p_asian-sd_asian, color='green')\n",
    "a1 = plt.scatter(x + 0.2, p_asian, color='green', label=\"Asian\")\n",
    "\n",
    "sd_afram = 1.96*np.sqrt(p_afram*(1-p_afram)/n_afram)\n",
    "plt.vlines(x, p_afram+sd_afram, p_afram-sd_afram, color='black')\n",
    "b1 = plt.scatter(x, p_afram, color='black', label=\"Black\")\n",
    "\n",
    "sd_white = 1.96*np.sqrt(p_white*(1-p_white)/n_white)\n",
    "plt.vlines(x+.1, p_white+sd_white, p_white-sd_white, color='blue')\n",
    "c1 = plt.scatter(x + 0.1, p_white, color='blue', label=\"White\")\n",
    "\n",
    "# a2 = plt.plot(x[1:] + 0.2, p_asian[1:], color = 'green')\n",
    "# b2 = plt.plot(x[1:], p_afram[1:], color='black')\n",
    "# c2 = plt.plot(x[1:] + 0.1, p_white[1:], color='blue')\n",
    "\n",
    "plt.ylabel('Loan Origination Status')\n",
    "plt.xlabel('Applicant Income Bracket')\n",
    "plt.xticks(range(-1,8))\n",
    "ax.legend([\"Asian\", \"Black\", \"White\"], bbox_to_anchor=(1.05, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abe Gong's hypothetical no bias plot\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "X = np.arange(-1,7)\n",
    "plt.plot(X, 100/(1+np.exp(.5*(5-X+np.random.uniform(size=8)))), color='blue')\n",
    "plt.plot(X, 100/(1+np.exp(.5*(5-X+np.random.uniform(size=8)))), color='black')\n",
    "plt.plot(X, 100/(1+np.exp(.5*(5-X+np.random.uniform(size=8)))), color='green')\n",
    "plt.title(\"Hypothetical conditional effect plot with no racial bias\")\n",
    "plt.ylabel('Loan Origination Status')\n",
    "plt.xlabel('Applicant Income Bracket')\n",
    "plt.xlim(0,max(X) + 1)\n",
    "plt.ylim(0,100)\n",
    "# plt.legend([\"White\", \"Black or AFAM\", \"Asian\"], loc='upper right')\n",
    "ax.legend([\"White\", \"Black or AFAM\", \"Asian\"], bbox_to_anchor=(1.4, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abe Gong's hypothetical biased plot\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "X = np.arange(-1,7)\n",
    "plt.plot(X, 100/(1+np.exp(.5*(3-X+np.random.uniform(size=8)))), color='blue')\n",
    "plt.plot(X, 100/(1+np.exp(.5*(5-X+np.random.uniform(size=8)))), color='black')\n",
    "plt.plot(X, 100/(1+np.exp(.5*(5-X+np.random.uniform(size=8)))), color='green')\n",
    "plt.title(\"Hypothetical conditional effect plot, biased against blacks or afam\")\n",
    "plt.ylabel('Loan Origination Status')\n",
    "plt.xlabel('Applicant Income Bracket')\n",
    "plt.xlim(0,12)\n",
    "plt.ylim(0,100)\n",
    "ax.legend([\"White\", \"Black or AFAM\", \"Asian\"], bbox_to_anchor=(1.4, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there were a systematic bias against nonwhite applicants, we would expect the plots below to look similar to this. They don't because it seems that the bias is more subtle than across the board discrimination. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using this data to automate loan approval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the 2015 New York State loan data, we'll train a logistic regression classifier to determine whether this apparent bias against African Americans (when we control solely for income) would still appear in a classifier that ideally would control for additional factors. In training this classifier, we'll exclude characteristics that are explicitly racially focused (race of applicant name, fraction of neighborhood that is a minority population, census tract, etc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sorted(df_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \n",
    "action_taken_name ~ applicant_income_000s + hud_median_family_income +  loan_amount_000s + number_of_1_to_4_family_units + number_of_owner_occupied_units + population + I\\[agency_abbr\\] + I\\[income_bracket\\] + I\\[lien_status_name\\] + I\\[loan_purpose_name\\] + I\\[loan_type_name\\] + I\\[owner_occupancy_name\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluded variables: \n",
    "\n",
    "* agency_name: redundant with agency_abbr\n",
    "* (co\\_)applicant\\_\\[ethnicity | race\\]\\_name\\_\\[1|2|3|4|5\\]: we're excluding explicitly racial characteristics from the regression\n",
    "* application_date_indicator: unlikely the time at which one applies should influence one's outcome\n",
    "* as_of_year: 2015 for all data points\n",
    "* census_tract_number: people's home/address is often highly correlated with their race so we will exclude this from the analysis.\n",
    "* county_name: census_tract is more specific\n",
    "* denial\\_reason\\_\\[1|2|3\\]: if this is not nan then the applicant was rejected and so it predicts the outcome almost always\n",
    "* hoepa_status_name: in all but 56 out of ~372k records this is \"Not a HOEPA loan\". Excluded b/c uninformative\n",
    "* minority_population: too much of a racial proxy\n",
    "* msamd_name: captured by the census tracts\n",
    "* preapproval_name: almost always nan\n",
    "* property_type_name: always \"One-to-four family dwelling\"\n",
    "* rate_spread: almost always nan and would be important but not populated until 2018 (unreleased) HMDA data set.\n",
    "* respondent_id: irrelevant. This is the lender's unique id\n",
    "* sequence_number: irrelevant. This is the loan id number\n",
    "* state_abbr: always \"NY\"\n",
    "* state_name: always \"New York\"\n",
    "* tract_to_msamd_income: if we include hud_median_family_income, tract_to_msamd_income is redundant because it says how many times greater a tract's income is relative to the median of the metro area, while hud captures the median income of the area. So they're highly correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variable that is denoted  I\\[$\\cdot$\\] is a discrete variable and so each of the possible values the categories could take on will be represented with an indicator variable.  All of the continuous variables are Z-Scored (demeaned and standardized) so that the result and coefficients of the logistic regression are interpretable, and no particular feature gets too much weight in the logistic regression or causes numerical problems because of the difference in the size of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding converts categorical variables into a form that is better for ML. \n",
    "# Specific value types are unique for each category.\n",
    "def oneHotFromCategory(rowValue, uniqueCategoryValues):\n",
    "    return np.array(list(map(lambda x: int(x == rowValue), uniqueCategoryValues)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuousVars = [\"applicant_income_000s\", \"hud_median_family_income\", \"loan_amount_000s\",\n",
    "               \"number_of_1_to_4_family_units\", \"number_of_owner_occupied_units\", \"population\"]\n",
    "\n",
    "discreteVars = [\"agency_abbr\", \"income_bracket\", \"lien_status_name\", \"loan_purpose_name\", \n",
    "                \"loan_type_name\", \"owner_occupancy_name\", \"purchaser_type_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for Logistic Regression\n",
    "Z-Scoring all the continuous variables and converting all of the discrete label data points into indicators takes time so we cache the transformed data as a pickled file.  If we have the pickled file, read that in. Otherwise generate a new version.  This takes a few minutes on our laptops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticFilename = 'logisticData_with_Dummies_2.pickle'\n",
    "logisticDataExists = os.path.isfile(logisticFilename)\n",
    "if logisticDataExists:\n",
    "    with open(logisticFilename, 'rb') as f:\n",
    "        logisticData = pickle.load(f)\n",
    "else:\n",
    "    logisticData = df_test[df_test.applicant_race_name_1.isin([Race.Asian, Race.Black, Race.White])]\\\n",
    "                   [[\"action_taken_name\"] + continuousVars + discreteVars].copy()\n",
    "    n0 = len(logisticData)\n",
    "    logisticData = logisticData.dropna()\n",
    "    for var in set(discreteVars) - set(['income_bracket']):\n",
    "        logisticData = logisticData[logisticData[var] != 'nan']\n",
    "    n1 = len(logisticData)\n",
    "    print(\"Start: %d\\tComplete: %d\\tDropped: %d (%.2f%%)\" % (n0, n1, n0 - n1, 100 * (n0 - n1) / float(n0)))\n",
    "\n",
    "    # # Z-Score Continuous Variables\n",
    "    for var in continuousVars:\n",
    "        logisticData[[var]] = (logisticData[[var]] - logisticData[[var]].mean()) /  logisticData[[var]].std()\n",
    "\n",
    "    # Add Dummy Variables for Discrete Variables\n",
    "    addDummiesFor = sorted(list(discreteVars))\n",
    "    for var in addDummiesFor:\n",
    "        sys.stdout.write(\"Starting: \"); sys.stdout.write(var); sys.stdout.write(\"\\t\")\n",
    "        u = sorted(logisticData[var].unique())\n",
    "        r = logisticData.apply(lambda x: oneHotFromCategory(x[var], u), axis = 1)\n",
    "        out = np.array([i for i in r.values])\n",
    "        logisticData = logisticData.join(pd.DataFrame(out, columns = u, index = logisticData.index))\n",
    "        sys.stdout.write(\"Finished: \"); sys.stdout.write(var); sys.stdout.write(\"\\n\")\n",
    "\n",
    "    with open(logisticFilename, 'wb') as f:\n",
    "        pickle.dump(logisticData, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shorten the names of the columns\n",
    "logisticDataColNames = {\n",
    "    1.0 : \"IncomeLevel_1\",\n",
    "    2.0 : \"IncomeLevel_2\",\n",
    "    3.0 : \"IncomeLevel_3\",\n",
    "    4.0 : \"IncomeLevel_4\",\n",
    "    5.0 : \"IncomeLevel_5\",\n",
    "    6.0 : \"IncomeLevel_6\",\n",
    "    7.0 : \"IncomeLevel_7\",\n",
    "    \"Not secured by a lien\" : \"LienUnsecured\",\n",
    "    \"Secured by a first lien\" : \"FirstLienSecured\",\n",
    "    \"Secured by a subordinate lien\" : \"SubordinateLienSecured\",\n",
    "    \"Home improvement\" : \"HomeImprovement\",\n",
    "    \"Home purchase\" : \"HomePurchase\",\n",
    "    \"FHA-insured\" : \"FHA_insured\",\n",
    "    \"FSA/RHS-guaranteed\" : \"FSA_RHS_guaranteed\",\n",
    "    'VA-guaranteed' : 'VA_guaranteed',\n",
    "    'Not owner-occupied as a principal dwelling' : \"NotOwnerOccupied\",\n",
    "    'Owner-occupied as a principal dwelling' : \"OwnerOccupied\",\n",
    "    'Affiliate institution' : \"AffiliateInstitution\",\n",
    "    'Commercial bank, savings bank or savings association' : \"CommercialBank\",\n",
    "    'Fannie Mae (FNMA)' : \"FannieMae\",\n",
    "    'Farmer Mac (FAMC)' : \"FarmerMac\",\n",
    "    'Freddie Mac (FHLMC)' : \"FreddieMac\",\n",
    "    'Ginnie Mae (GNMA)' : \"GinnieMae\",\n",
    "    'Life insurance company, credit union, mortgage bank, or finance company' : \"LifeInsurance\",\n",
    "    'Loan was not originated or was not sold in calendar year covered by register' : \"WrongYear\",\n",
    "    'Other type of purchaser' : \"OtherPurchaser\",\n",
    "    'Private securitization' : \"PrivateSecuritization\"\n",
    "}\n",
    "logisticData = logisticData.rename(logisticDataColNames, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the logistic regression model with the above features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4321) # use the same seed to ensure we get the same training data every time\n",
    "trainData, testData = train_test_split(logisticData, test_size=0.2)\n",
    "\n",
    "X_train = trainData.drop(discreteVars + [\"action_taken_name\"] , axis = 1)\n",
    "y_train_binary = trainData.action_taken_name\n",
    "\n",
    "X_test = testData.drop(discreteVars + [\"action_taken_name\"] , axis = 1)\n",
    "y_test_binary = testData.action_taken_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = Logit(solver = \"lbfgs\", max_iter = 1000)\n",
    "binary_model.fit(X_train.values, y_train_binary.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_predictions = binary_model.predict(X_test.values)\n",
    "\n",
    "accuracy = sum(list(map(lambda x: int(x), (logit_predictions == y_test_binary)))) / len(X_test)\n",
    "print(\"Accuracy rate of trained model: %0.2f%%\" % (accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just as a quick sanity check to make sure the model gives reasonable results, the print out below shows that as a respondent moves into higher income brackets, the better the applicant's chances become at being approved for a loan, all else equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelValues = pd.DataFrame(np.array([X_test.columns.values, binary_model.coef_[0]]).T, \n",
    "             columns = [\"parameterName\", \"coef\"])\n",
    "modelValues[modelValues.parameterName.isin([\"IncomeLevel_%d\" % i for i in range(1,8)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(x):\n",
    "    return x != x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To see if our classifier is biased against certain races, we will group the predictions for each racial group into 10 groups [0,0.1], ... [0.9,1.0] and then see if for each group, the true probability of receiving a loan varied by race. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe that computes the true approval rating for each decile \n",
    "def createRaceAndProbData(df_test, binary_model, X_test):\n",
    "    originalWithProbs = df_test\\\n",
    "    .join(pd.DataFrame(binary_model.predict_proba(X_test)[:,1], \n",
    "                       columns = [\"probOfAcceptance\"], index = X_test.index))\n",
    "    originalWithProbs = originalWithProbs[~isNaN(originalWithProbs.probOfAcceptance)]\n",
    "\n",
    "    # Group approval probabilities by race and then by decile\n",
    "    raceAndProbData = originalWithProbs[originalWithProbs.applicant_race_name_1.isin(\n",
    "                      [Race.Asian, Race.Black, Race.White])]\\\n",
    "                      [[\"applicant_race_name_1\", \"probOfAcceptance\", \"action_taken_name\"]]\\\n",
    "                      .sort_values([\"probOfAcceptance\"], ascending = False)\n",
    "\n",
    "    raceAndProbData[\"probBucket\"] = raceAndProbData.probOfAcceptance.apply(lambda x: round((x + 0.0499999999) * 10))\n",
    "    means = raceAndProbData\\\n",
    "    .groupby([\"applicant_race_name_1\", \"probBucket\"])\\\n",
    "    .action_taken_name\\\n",
    "    .mean()\\\n",
    "    .reset_index(name = \"meanAcceptance\")\\\n",
    "    .set_index([\"applicant_race_name_1\", \"probBucket\"])\n",
    "\n",
    "    raceAndProbData = raceAndProbData.set_index([\"applicant_race_name_1\", \"probBucket\"])\n",
    "    raceAndProbData[\"meanAcceptance\"] = means.meanAcceptance\n",
    "    raceAndProbData = raceAndProbData.reset_index()\n",
    "\n",
    "    raceAndProbData[\"predictedOutcome\"] = raceAndProbData.probOfAcceptance.apply(lambda x: int(x >= 0.5))\n",
    "\n",
    "    del(means)\n",
    "    return raceAndProbData "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the actual approval rates by racial group against the rates that our model predicts\n",
    "def plotTrueVsPredictedApprovalByRace(raceAndProbData, raceIncluded = False):\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    asianData = raceAndProbData[raceAndProbData.applicant_race_name_1 == Race.Asian][[\"probBucket\", \"meanAcceptance\"]]\\\n",
    "                .drop_duplicates().reset_index()\n",
    "    blackData = raceAndProbData[raceAndProbData.applicant_race_name_1 == Race.Black][[\"probBucket\", \"meanAcceptance\"]]\\\n",
    "                .drop_duplicates().reset_index()\n",
    "    whiteData = raceAndProbData[raceAndProbData.applicant_race_name_1 == Race.White][[\"probBucket\", \"meanAcceptance\"]]\\\n",
    "                .drop_duplicates().reset_index()\n",
    "\n",
    "    plt.scatter(asianData.probBucket, asianData.meanAcceptance, label = \"Asian\", color = 'g')\n",
    "    plt.scatter(blackData.probBucket, blackData.meanAcceptance, label = \"Black\", color = 'k')\n",
    "    plt.scatter(whiteData.probBucket, whiteData.meanAcceptance, label = \"White\", color = 'b')\n",
    "\n",
    "    plt.xlabel(\"Predicted Probability of Acceptance\")\n",
    "    plt.ylabel(\"True Probability of Acceptance\")\n",
    "    if raceIncluded:\n",
    "        plt.title(\"True Acceptance vs. Predicted Acceptance By Race\\n(Race Included)\")\n",
    "    else:\n",
    "        plt.title(\"True Acceptance vs. Predicted Acceptance By Race\")\n",
    "    plt.xticks(range(1,11))\n",
    "    ax.legend(['Asian', 'Black or African American', 'White'], bbox_to_anchor=(1.1, 1.0))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the difference between Asian and Black approval ratings relative to Whites after grouping by the \n",
    "# predicted likelihood of approval\n",
    "def plotApprovalDifferences(raceAndProbData, raceIncluded = False):\n",
    "    asianData = raceAndProbData[raceAndProbData.applicant_race_name_1 == Race.Asian][[\"probBucket\", \"meanAcceptance\"]].drop_duplicates().reset_index()\n",
    "    blackData = raceAndProbData[raceAndProbData.applicant_race_name_1 == Race.Black][[\"probBucket\", \"meanAcceptance\"]].drop_duplicates().reset_index()\n",
    "    whiteData = raceAndProbData[raceAndProbData.applicant_race_name_1 == Race.White][[\"probBucket\", \"meanAcceptance\"]].drop_duplicates().reset_index()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    plt.scatter(asianData.probBucket, asianData.meanAcceptance - whiteData.meanAcceptance, label = \"Asian\", color='g')\n",
    "    plt.scatter(blackData.probBucket, blackData.meanAcceptance - whiteData.meanAcceptance, label = \"Black\", color='k')\n",
    "\n",
    "    plt.xlabel(\"Predicted Probability of Acceptance\")\n",
    "    plt.ylabel(\"Difference in Acceptance Rel. TO Whites\")\n",
    "    ax.legend(['Asian', 'Black or African American'], bbox_to_anchor=(1.6, 1.0))\n",
    "    if raceIncluded:\n",
    "        plt.title(\"True Acceptance Probability Relative to Whites\\n(Race Included)\")\n",
    "    else: \n",
    "        plt.title(\"True Acceptance Probability Relative to Whites\")\n",
    "    ax.axhline(y = 0, color = 'b')\n",
    "    plt.xticks(range(1,11))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceAndProbData = createRaceAndProbData(df_test, binary_model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrueVsPredictedApprovalByRace(raceAndProbData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After controlling for many factors, Blacks are persistently approved at lower rates\n",
    "\n",
    "On the x-axis, we use the logistic regression model trained above to generate the probability that a loan applicant in our test set was approved for a loan and then grouped each applicant by the probability decile they were predicted to belong to.  Then, once individuals were grouped into 10 groups, we computed the actual fraction of each group by racial group that was accepted. For example, the points above x = 2 indicate that for Whites who were predicted to have between a 10% and 20% chance of being approved were actual approved about 16% of the time. The difference in approval is clearest for the candidates who have qualities that make them neither a clear approval or a clear rejection.  Whites and Asians who are in Group 6 had just under a 60% true approval rating which is a little higher than we might expect given that this contained everyone who the model predicted would be  approved 50-60% of the time.  However, Blacks who had qualities that put them in Group 6 were in fact only approved 40% of the time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotApprovalDifferences(raceAndProbData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the difference\n",
    "This plot shows the difference between asian and black approval rates relative to whites in the same group.  If you take the previous plot and subtract the White sereis from the Asian series and the Black series, then the values you get would be this plot. Again at the extreme ends of the distribution, discrimination is virtually nonexistent but for the middle it seem quite likely that race is taken into account when approving loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does including race in the regression eliminate this apparent bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rerun the same analysis but include the applicant_race_name_1 as a proxy for race. Data is process in the same way. Only difference is that race is now a variable in the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticWithRaceFilename = 'logisticDataWithRace.pickle'\n",
    "logisticDataWithRaceExists = os.path.isfile(logisticWithRaceFilename)\n",
    "if logisticDataWithRaceExists:\n",
    "    with open(logisticWithRaceFilename, 'rb') as f:\n",
    "        logisticDataWithRace = pickle.load(f)\n",
    "else:\n",
    "    logisticDataWithRace = df_test[df_test.applicant_race_name_1.isin([Race.Asian, Race.Black, Race.White])]\\\n",
    "                   [[\"action_taken_name\", \"applicant_race_name_1\"] + continuousVars + discreteVars].copy()\n",
    "    n0 = len(logisticDataWithRace)\n",
    "    # Drop entries with na's which must be float(\"nan\")\n",
    "    logisticDataWithRace = logisticDataWithRace.dropna()\n",
    "    # drop entries that have the string \"nan\" as a result of pre-processing conversion to csv\n",
    "    # we filter out Race.nan's above\n",
    "    for var in set(discreteVars) - set(['income_bracket']):\n",
    "        logisticDataWithRace = logisticDataWithRace[logisticDataWithRace[var] != 'nan']\n",
    "    n1 = len(logisticDataWithRace)\n",
    "    print(\"Start: %d\\tComplete: %d\\tDropped: %d (%.2f%%)\" % (n0, n1, n0 - n1, 100 * (n0 - n1) / float(n0)))\n",
    "\n",
    "    # # Z-Score Continuous Variables\n",
    "    for var in continuousVars:\n",
    "        logisticDataWithRace[[var]] = ((logisticDataWithRace[[var]] - logisticDataWithRace[[var]].mean()) \n",
    "        /  logisticDataWithRace[[var]].std())\n",
    "\n",
    "    # Add Dummy Variables for Discrete Variables\n",
    "    addDummiesFor = sorted(list(discreteVars) + [\"applicant_race_name_1\"])\n",
    "    for var in addDummiesFor:\n",
    "        sys.stdout.write(\"Starting: \"); sys.stdout.write(var); sys.stdout.write(\"\\t\")\n",
    "        u = sorted(logisticDataWithRace[var].unique())\n",
    "        r = logisticDataWithRace.apply(lambda x: oneHotFromCategory(x[var], u), axis = 1)\n",
    "        out = np.array([i for i in r.values])\n",
    "        logisticDataWithRace = logisticDataWithRace.join(pd.DataFrame(out, columns = u, \n",
    "                                                                      index = logisticDataWithRace.index))\n",
    "        sys.stdout.write(\"Finished: \"); sys.stdout.write(var); sys.stdout.write(\"\\n\")\n",
    "\n",
    "    with open(logisticWithRaceFilename, 'wb') as f:\n",
    "        pickle.dump(logisticDataWithRace, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "logisticDataWithRace = logisticDataWithRace.rename(logisticDataColNames, axis = 1)\n",
    "logisticDataWithRace = logisticDataWithRace.rename({Race.Asian : \"Asian\", Race.Black: \"Black\", \n",
    "                                                    Race.White: \"White\"}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4321) # use the same seed to ensure we get the same training data every time\n",
    "trainDataRace, testDataRace = train_test_split(logisticDataWithRace, test_size=0.2)\n",
    "\n",
    "X_train_race = trainDataRace.drop(discreteVars + [\"action_taken_name\", \"applicant_race_name_1\"] , axis = 1)\n",
    "y_train_binary_race = trainDataRace.action_taken_name\n",
    "\n",
    "X_test_race = testDataRace.drop(discreteVars + [\"action_taken_name\", \"applicant_race_name_1\"] , axis = 1)\n",
    "y_test_binary_race = testDataRace.action_taken_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model_with_race = Logit(solver = \"lbfgs\", max_iter = 1000)\n",
    "binary_model_with_race.fit(X_train_race.values, y_train_binary_race.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceAndProbDataRaceIncluded = createRaceAndProbData(df_test, binary_model_with_race, X_test_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotTrueVsPredictedApprovalByRace(raceAndProbDataRaceIncluded, raceIncluded = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotApprovalDifferences(raceAndProbDataRaceIncluded, raceIncluded = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling for race does eliminate differential approval ratings\n",
    "### Evidence that there is discrimination\n",
    "\n",
    "What these two plots show is that by including race in our model, we no longer see any sort of systematic bias against each racial group.  This is evidence that there is not some other confounding factor that we have accounted for, or at least this shows that if there is some confounding, unobserved variable that could explain the difference seen above in approval rating it is highly correlated with race.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelValuesWithRace = pd.DataFrame(np.array([X_test_race.columns.values, binary_model_with_race.coef_[0]]).T, \n",
    "             columns = [\"parameterName\", \"coef\"])\n",
    "\n",
    "print(modelValuesWithRace[modelValuesWithRace.parameterName.isin([\"Asian\", \"Black\", \"White\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that blacks face lower approval ratings is clearly reflected in these coefficients because the coefficient on the model parameters the corresponds to whether a loan applicant is black has a negative coefficient, while a white applicant has a positive coefficient.  Being Asian does not significantly improve or hurt one's chances at being approved according to this model's coefficients, in fact there is a weakly positive association between being Asian and being approved, though it is not as strong as the relationship for Whites. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatrix(racesToInclude = list(raceAndProbData.applicant_race_name_1.unique())):\n",
    "    actual_pos = (raceAndProbData.action_taken_name == 1.0); actual_neg = (raceAndProbData.action_taken_name == 0.0);\n",
    "    pred_pos = (raceAndProbData.predictedOutcome == 1.0); pred_neg = (raceAndProbData.predictedOutcome == 0.0);\n",
    "    \n",
    "    racialFilter = raceAndProbData.applicant_race_name_1.isin(racesToInclude)\n",
    "\n",
    "    true_positives = len(raceAndProbData[actual_pos & pred_pos & racialFilter])\n",
    "    true_negatives = len(raceAndProbData[actual_neg & pred_neg & racialFilter])\n",
    "    false_positives = len(raceAndProbData[actual_neg & pred_pos & racialFilter])\n",
    "    false_negatives = len(raceAndProbData[actual_pos & pred_neg & racialFilter])\n",
    "\n",
    "    TPR = true_positives / (true_positives + false_negatives)\n",
    "    FPR = false_positives / (true_negatives + false_positives) # 1 - TNR\n",
    "    TNR = true_negatives / (true_negatives + false_positives)\n",
    "    FNR = false_negatives / (true_positives + false_negatives) # 1 - TPR\n",
    "\n",
    "    print(\"\"\"\n",
    "            Act.Pos | Act.Neg \n",
    "          #-------------------#\n",
    "          |         |         |\n",
    "    Pred. |  (TPR)  |  (FPR)  |\n",
    "    Pos   |  %0.3f  |  %0.3f  | \n",
    "          |         |         |\n",
    "    ------|---------#---------|\n",
    "          |         |         |\n",
    "    Pred. |  (FNR)  |  (TNR)  |\n",
    "    Neg   |  %0.3f  |  %0.3f  |\n",
    "          |         |         |\n",
    "          #-------------------#\n",
    "    \"\"\" % (TPR, FPR, FNR, TNR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getConfusionMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getConfusionMatrix([Race.Asian])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getConfusionMatrix([Race.Black])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getConfusionMatrix([Race.White])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Analysis\n",
    "\n",
    "Our classifier treats Whites and Asians virtually identically from a confusion matrix perspective. However, our classifier is less likely to \"mistakenly\" approve a black applicant for a loan (the False Positive Rate for Blacks is 19%, compared to 35% for whites) and more likely to \"mistakenly\" reject a black applicant for a loan (the False Negative Rate for Blacks is 9.4%, compared to 7.4% for Whites). These discrepancies are most prevalent in the ~50% probability of loan origination/purchased by an institution range. The story behind these results may be that in cases in which it is unclear as to whether a loan applicant should be approved (when the model says they have a 50% probability of approval), loan officers consciously or not give the benefit of the doubt to White and Asian applicants but not to black applicants.  For applicants who have characteristics that the model views as being nearly automatic qualifiers or disqualifiers for a loan, loan officers either definitively know what to do in these cases or, more cynically, do not have any room to discriminate against different applicants because such an action could clearly be perceived as discriminatory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
