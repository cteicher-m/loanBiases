{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will utilize our pre-processed and cleaned data set in order to answer our research question: \n",
    "### Is lending racially discriminatory in the US?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv from pre-processing. We must re-cast types because they were converted to strings upon exporting. \n",
    "df = pd.read_csv(\"encoded_loan_data.csv\", sep=',', engine='python', error_bad_lines=False, dtype='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(df.applicant_race_name_1.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define immutable, related set of constant values.\n",
    "import enum\n",
    "from functools import total_ordering\n",
    "@total_ordering\n",
    "class Race(enum.Enum):\n",
    "    Native = 'American Indian or Alaska Native'\n",
    "    Asian = 'Asian'\n",
    "    Black = 'Black or African American'\n",
    "    PacificIslander = 'Native Hawaiian or Other Pacific Islander'\n",
    "    White = 'White'\n",
    "    nan = 'nan'\n",
    "    def __lt__(self, other):\n",
    "        if self.__class__ is other.__class__:\n",
    "            return self.value < other.value\n",
    "        return NotImplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before visualizing this data we must ensure all processed data is numeric. These column types match those discussed in pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colToType = {\n",
    "    \"tract_to_msamd_income\" : float, \n",
    "    \"rate_spread\" : float,\n",
    "    \"population\" : int,\n",
    "    \"minority_population\" : bool,\n",
    "    \"number_of_owner_occupied_units\" : int, \n",
    "    \"number_of_1_to_4_family_units\" : int, \n",
    "    \"loan_amount_000s\" : float, \n",
    "    \"hud_median_family_income\" : float,\n",
    "    \"applicant_income_000s\" : float,\n",
    "    \"sequence_number\" : int, \n",
    "    \"census_tract_number\" : float, \n",
    "    \"as_of_year\" : int,\n",
    "    \"application_date_indicator\" : int, \n",
    "    \"applicant_race_name_1\": Race,\n",
    "    \"applicant_race_name_2\": Race,\n",
    "    \"applicant_race_name_3\": Race,\n",
    "    \"applicant_race_name_4\": Race,\n",
    "    \"applicant_race_name_5\": Race,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert aforementioned column types\n",
    "df_test = df\n",
    "# Use Pandas drop_duplicates() as evidence that dataset is deduplicated\n",
    "print(\"Deduplicated Valid Rows: %d\\tFully Deduplicated: %r\" \n",
    "      % (len(df_test), len(df_test) == len(df_test.drop_duplicates())))\n",
    "print(\"Columns: %d\" % len(df_test.columns.values))\n",
    "\n",
    "# Convert types of columns\n",
    "for colName, colType in colToType.items():\n",
    "    if colType == int:\n",
    "        df_test[colName] = df_test[colName].apply(lambda x: x if x != 'nan' else 0).astype(int)\n",
    "    elif colType == float:\n",
    "        df_test[colName] = df_test[colName].apply(lambda x: x if x != 'nan' else float('nan')).astype(float)\n",
    "    elif colType == Race:\n",
    "        df_test[colName] = df_test[colName].apply(lambda x: Race(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column types were correctly converted\n",
    "assert [col in ['int64','float'] for col in [df[y].dtype for y in numeric_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.applicant_race_name_1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the samples for Native Americans and Pacific Islanders are so small, we will exclude them for much of the analysis that is testing the effects of race on mortgage approval status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name each income bucket in order to plot data \n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(0, 18]', 1)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(18, 75]', 2)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(75, 153]', 3)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(153, 233]', 4)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(233, 416]', 5)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(416, 470]', 6)\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('(470, 9999]', 7)\n",
    "# Applicants with no income reported will be meaningless in our analysis and will be indicated in the -1 column.\n",
    "df[\"income_bracket\"] = df[\"income_bracket\"].replace('nan', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## DO WE NEED THIS \n",
    " <span style=\"color:red\">below</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"income_bracket\"] = df[\"income_bracket\"].astype('float')\n",
    "df[\"action_taken_name\"] = df[\"action_taken_name\"].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data frames to run analyses on gender disaggregated data\n",
    "df_gender_male = df.copy()\n",
    "df_gender_female = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applicant income histogram\n",
    "df.income_bracket.hist(bins = range(-1,8))\n",
    "plt.title('Applicant Income')\n",
    "plt.xlabel('All Applicant Incomes')\n",
    "plt.ylabel('Number of applicants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all female data\n",
    "df_gender_male = df_gender_male.drop(df_gender_male[df_gender_male.applicant_sex_name == \"Female\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all male data \n",
    "df_gender_female = df_gender_female.drop(df_gender_female[df_gender_female.applicant_sex_name == \"Male\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applicant income for male histogram\n",
    "df_gender_male.income_bracket.hist(bins = range(-1,8))\n",
    "plt.title('Male Applicant Income')\n",
    "plt.xlabel('All male applicant incomes')\n",
    "plt.ylabel('Number of applicants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applicant income for women histogram\n",
    "df_gender_female.income_bracket.hist(bins = range(-1,8))\n",
    "plt.title('Female Applicant Income')\n",
    "plt.xlabel('All Female applicant incomes')\n",
    "plt.ylabel('Number of applicants')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Graph loan frequency of originated loan/purchased by institution for each income bracket\n",
    "# disaggregated by race  \n",
    "fig = plt.figure()\n",
    "ax = df[(df.applicant_race_name_1 != Race.nan)]\\\n",
    ".groupby([\"applicant_race_name_1\", \"income_bracket\"])\\\n",
    ".action_taken_name.mean()\\\n",
    ".reset_index().set_index([\"income_bracket\", \"applicant_race_name_1\"])\\\n",
    ".unstack(\"applicant_race_name_1\")\\\n",
    ".rename_axis([None, \"applicant_race_name_1\"], axis = 1).plot.bar(color = 'ygkrb')\n",
    "\n",
    "plt.title('Loan status by income, conditional on race')\n",
    "plt.xlabel('Income Bracket')\n",
    "plt.ylabel('Loan Origination Status')\n",
    "ax.legend(['Native American', 'Asian', 'Black or African American'\n",
    "           ,'Pacific Islander','White'], bbox_to_anchor=(1.1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph loan frequency of originated loan/purchased by institution for each income bracket\n",
    "# disaggregated by race only for Asian, Black, and White\n",
    "fig = plt.figure()\n",
    "ax = df[~(df.applicant_race_name_1.isin([Race.nan, Race.Native, Race.PacificIslander]))]\\\n",
    ".groupby([\"applicant_race_name_1\", \"income_bracket\"])\\\n",
    ".action_taken_name.mean()\\\n",
    ".reset_index().set_index([\"income_bracket\", \"applicant_race_name_1\"])\\\n",
    ".unstack(\"applicant_race_name_1\")\\\n",
    ".rename_axis([None, \"applicant_race_name_1\"], axis = 1).plot.bar(color = 'gkb')\n",
    "\n",
    "plt.title('Loan status by income, conditional on race')\n",
    "plt.xlabel('Income Bracket')\n",
    "plt.ylabel('Loan Origination Status')\n",
    "ax.legend(['Asian', 'Black or African American', 'White'], bbox_to_anchor=(1.1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance between asian and white, black and white, frequencies of originated loans/purchased by institution \n",
    "whiteMeans = df[(df.applicant_race_name_1 == Race.White) & (df.income_bracket > 0)].groupby([\"applicant_race_name_1\", \"income_bracket\"])\\\n",
    ".action_taken_name.mean().reset_index().set_index(\"income_bracket\").drop(\"applicant_race_name_1\", axis = 1)\n",
    "\n",
    "asianMeans = df[(df.applicant_race_name_1 == Race.Asian) & (df.income_bracket > 0)].groupby([\"applicant_race_name_1\", \"income_bracket\"])\\\n",
    ".action_taken_name.mean().reset_index().set_index(\"income_bracket\").drop(\"applicant_race_name_1\", axis = 1)\n",
    "\n",
    "blackMeans = df[(df.applicant_race_name_1 == Race.Black) & (df.income_bracket > 0)].groupby([\"applicant_race_name_1\", \"income_bracket\"])\\\n",
    ".action_taken_name.mean().reset_index().set_index(\"income_bracket\").drop(\"applicant_race_name_1\", axis = 1)\n",
    "\n",
    "asianDiffRelWhites = (asianMeans - whiteMeans).mean()\n",
    "blackDiffRelWhites = (blackMeans - whiteMeans).mean()\n",
    "\n",
    "print(\"After controlling for income, asians were %0.2f%% less likely to get a loan approved relative to whites.\" % \n",
    "      (asianDiffRelWhites * 100))\n",
    "print(\"After controlling for income, blacks were %0.2f%% less likely to get a loan approved relative to whites.\" %\n",
    "      (blackDiffRelWhites * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same graph but exclusively for primary male applicants\n",
    "fig = plt.figure()\n",
    "ax = df[df.applicant_race_name_1.isin([Race.Asian, Race.Black, Race.White])]\\\n",
    ".groupby([\"applicant_race_name_1\", \"income_bracket\"]).action_taken_name\\\n",
    ".mean()\\\n",
    ".reset_index().set_index([\"income_bracket\", \"applicant_race_name_1\"])\\\n",
    ".unstack(\"applicant_race_name_1\")\\\n",
    ".plot.bar(color = 'gkb')\n",
    "\n",
    "ax.legend([\"Asian\", \"Black or African American\", \"White\"], bbox_to_anchor=(1.1, 1.0))\n",
    "plt.title('Loan status by income, conditional on race for Male Applicants')\n",
    "plt.xlabel('Income Bracket')\n",
    "plt.ylabel('Loan status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same graph but exclusively for primary female applicants\n",
    "fig = plt.figure()\n",
    "ax = df_gender_female[df_gender_female.applicant_race_name_1.isin([Race.Asian, Race.Black, Race.White])]\\\n",
    ".groupby([\"applicant_race_name_1\", \"income_bracket\"]).action_taken_name\\\n",
    ".mean()\\\n",
    ".reset_index().set_index([\"income_bracket\", \"applicant_race_name_1\"])\\\n",
    ".unstack(\"applicant_race_name_1\")\\\n",
    ".plot.bar(color = 'gkb')\n",
    "\n",
    "plt.title('Loan status by income, conditional on race for Female Applicants')\n",
    "plt.xlabel('Income Bracket')\n",
    "plt.ylabel('Loan status')\n",
    "ax.legend(['Asian', 'Black or African American','White'], bbox_to_anchor=(1.1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the mean number of application results for each race, we see for any income bracket, aside from one of the higher income brackets, there is a consistent discrepancy between loan status and race. Black or African American applicants were denied loan applications more frequently than white applicants. The amount by which the number of applicants with originated loans differ, is inconsistent between different races and across different income brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of Native Hawaiian or Other Pacific Islander and American Indian applicants is low. As a result the confidence intervals for the following plot will be too large in order to gauage meaningful analyses with regards to race and application status?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loan status proportions and counts by applicant race and income bracket.\n",
    "p_afram = df[df.applicant_race_name_1== Race.Black].groupby('income_bracket').action_taken_name.mean()\n",
    "n_afram = df[df.applicant_race_name_1== Race.Black].groupby('income_bracket').action_taken_name.count()\n",
    "\n",
    "p_white = df[df.applicant_race_name_1== Race.White].groupby('income_bracket').action_taken_name.mean()\n",
    "n_white = df[df.applicant_race_name_1== Race.White].groupby('income_bracket').action_taken_name.count()\n",
    "\n",
    "p_asian = df[df.applicant_race_name_1== Race.Asian].groupby('income_bracket').action_taken_name.mean()\n",
    "n_asian = df[df.applicant_race_name_1== Race.Asian].groupby('income_bracket').action_taken_name.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_afram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the proportions with 1-SD error bars\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "x = np.array([-1] + list(range(1,8)))\n",
    "\n",
    "sd_asian = 1.96*np.sqrt(p_asian*(1-p_asian)/n_asian)\n",
    "plt.vlines(x+.2, p_asian+sd_asian, p_asian-sd_asian, color='green')\n",
    "a1 = plt.scatter(x + 0.2, p_asian, color='green', label=\"Asian\")\n",
    "\n",
    "sd_afram = 1.96*np.sqrt(p_afram*(1-p_afram)/n_afram)\n",
    "plt.vlines(x, p_afram+sd_afram, p_afram-sd_afram, color='black')\n",
    "b1 = plt.scatter(x, p_afram, color='black', label=\"Black\")\n",
    "\n",
    "sd_white = 1.96*np.sqrt(p_white*(1-p_white)/n_white)\n",
    "plt.vlines(x+.1, p_white+sd_white, p_white-sd_white, color='blue')\n",
    "c1 = plt.scatter(x + 0.1, p_white, color='blue', label=\"White\")\n",
    "\n",
    "# a2 = plt.plot(x[1:] + 0.2, p_asian[1:], color = 'green')\n",
    "# b2 = plt.plot(x[1:], p_afram[1:], color='black')\n",
    "# c2 = plt.plot(x[1:] + 0.1, p_white[1:], color='blue')\n",
    "\n",
    "plt.ylabel('Loan Origination Status')\n",
    "plt.xlabel('Applicant Income Bracket')\n",
    "plt.xticks(range(-1,8))\n",
    "ax.legend([\"Asian\", \"Black\", \"White\"], bbox_to_anchor=(1.05, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abe Gong's hypothetical no bias plot\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "X = np.arange(-1,7)\n",
    "plt.plot(X, 100/(1+np.exp(.5*(5-X+np.random.uniform(size=8)))), color='blue')\n",
    "plt.plot(X, 100/(1+np.exp(.5*(5-X+np.random.uniform(size=8)))), color='black')\n",
    "plt.plot(X, 100/(1+np.exp(.5*(5-X+np.random.uniform(size=8)))), color='green')\n",
    "plt.title(\"Hypothetical conditional effect plot with no racial bias\")\n",
    "plt.ylabel('Loan Origination Status')\n",
    "plt.xlabel('Applicant Income Bracket')\n",
    "plt.xlim(0,max(X) + 1)\n",
    "plt.ylim(0,100)\n",
    "# plt.legend([\"White\", \"Black or AFAM\", \"Asian\"], loc='upper right')\n",
    "ax.legend([\"White\", \"Black or AFAM\", \"Asian\"], bbox_to_anchor=(1.4, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abe Gong's hypothetical biased plot\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "X = np.arange(-1,7)\n",
    "plt.plot(X, 100/(1+np.exp(.5*(3-X+np.random.uniform(size=8)))), color='blue')\n",
    "plt.plot(X, 100/(1+np.exp(.5*(5-X+np.random.uniform(size=8)))), color='black')\n",
    "plt.plot(X, 100/(1+np.exp(.5*(5-X+np.random.uniform(size=8)))), color='green')\n",
    "plt.title(\"Hypothetical conditional effect plot, biased against blacks or afam\")\n",
    "plt.ylabel('Loan Origination Status')\n",
    "plt.xlabel('Applicant Income Bracket')\n",
    "plt.xlim(0,12)\n",
    "plt.ylim(0,100)\n",
    "ax.legend([\"White\", \"Black or AFAM\", \"Asian\"], bbox_to_anchor=(1.4, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I don't even think we these two graphs below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "X = np.arange(-1,7)\n",
    "#what is X2 numbers probably aren't right for this\n",
    "X2 = np.array([1,1,1,1,0,0,0,0,])\n",
    "plt.plot(X, 100/(1+np.exp(.5*(3-X+np.random.uniform(size=8)))), color='blue')\n",
    "plt.plot(X, 100/(1+np.exp(.5*(3-X+3*X2+np.random.uniform(size=8)))), color='black')\n",
    "plt.plot(X, 100/(1+np.exp(.5*(3-X+3*X2+np.random.uniform(size=8)))), color='green')\n",
    "plt.title(\"Hypothetical conditional effect plot, biased against low-risk black applicants\")\n",
    "plt.ylabel('Loan Origination Status')\n",
    "plt.xlabel('Applicant Income Bracket')\n",
    "plt.xlim(0,max(X) + 1)\n",
    "plt.ylim(0,100)\n",
    "ax.legend([\"White\", \"Black or AFAM\", \"Asian\"], bbox_to_anchor=(1.4, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "X = np.arange(-1,7)\n",
    "#what is X2 numbers probably aren't right for this\n",
    "X2 = np.array([0,0,0,.2,.4,.8,1,1.2,])\n",
    "plt.plot(X, 100/(1+np.exp(.5*(3-X+np.random.uniform(size=8)))), color='blue')\n",
    "plt.plot(X, 100/(1+np.exp(.5*(3-X+4*X2+np.random.uniform(size=8)))), color='black')\n",
    "plt.plot(X, 100/(1+np.exp(.5*(3-X+4*X2+np.random.uniform(size=8)))), color='green')\n",
    "plt.title(\"Hypothetical conditional effects plot, biased against high-risk black applicants\")\n",
    "plt.ylabel('Loan Origination Status')\n",
    "plt.xlabel('Applicant Income Bracket')\n",
    "plt.xlim(0,max(X) + 1)\n",
    "plt.ylim(0,100)\n",
    "ax.legend([\"White\", \"Black or AFAM\", \"Asian\"], bbox_to_anchor=(1.4, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using this data to automate loan approval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using the 2015 New York State loan data, we'll train a logistic regression classifier to determine whether this apparent bias against African Americans (when we control solely for income) would still appear in a classifier that ideally would control for additional factors. In training this classifier, we'll exclude characteristics that are explicitly racially focused (race of applicant name, fraction of neighborhood that is a minority population, etc).  While there are some characteristics that correlate with race such as census tract, we will include those because they're not explcitly racial and are on mortgage applications – after all, lenders need to know where the houses they are providing loans for are located. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression as Logit\n",
    "from sklearn.linear_model import LinearRegression as OLS\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sorted(df_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \n",
    "action_taken_name ~ applicant_income_000s + hud_median_family_income +  loan_amount_000s + number_of_1_to_4_family_units + number_of_owner_occupied_units + population + I\\[agency_abbr\\] + I\\[census_tract_number\\] + I\\[income_bracket\\] + I\\[lien_status_name\\] + I\\[loan_purpose_name\\] + I\\[loan_type_name\\] + I\\[owner_occupancy_name\\] + I\\[purchaser_type_name\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluded variables: \n",
    "\n",
    "* agency_name: redundant with agency_abbr\n",
    "* (co\\_)applicant\\_\\[ethnicity | race\\]\\_name\\_\\[1|2|3|4|5\\]: we're excluding explicitly racial characteristics from the regression\n",
    "* application_date_indicator: unlikely the time at which one applies should influence one's outcome\n",
    "* as_of_year: 2015 for all data points\n",
    "* census_tract_number: people's home/address is often highly correlated with their race so we will exclude this from the analysis.\n",
    "* county_name: census_tract is more specific\n",
    "* denial\\_reason\\_\\[1|2|3\\]: if this is not nan then the applicant was rejected and so it predicts the outcome almost always\n",
    "* hoepa_status_name: in all but 56 out of ~372k records this is \"Not a HOEPA loan\". Excluded b/c uninformative\n",
    "* minority_population: too much of a racial proxy\n",
    "* msamd_name: captured by the census tracts\n",
    "* preapproval_name: almost always nan\n",
    "* property_type_name: always \"One-to-four family dwelling\"\n",
    "* rate_spread: almost always nan and would be important but not populated until 2018 (unreleased) HMDA data set.\n",
    "* respondent_id: irrelevant. This is the lender's unique id\n",
    "* sequence_number: irrelevant. This is the loan id number\n",
    "* state_abbr: always \"NY\"\n",
    "* state_name: always \"New York\"\n",
    "* tract_to_msamd_income: if we include hud_median_family_income, tract_to_msamd_income is redundant because it says how many times greater a tract's income is relative to the mediann of the metro area, while hud captures the median income of the area. So they're highly correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variable that is denoted  I\\[$\\cdot$\\] is a discrete variable and so each of the possible values the categories could take on will be represented with an indicator variable.  All of the continuous variables are Z-Scored so that the result and coefficients of the logistic regression are interpretable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding converts categorical variables into a form that is better for ML. \n",
    "# Specific value types are unique for each category.\n",
    "def oneHotFromCategory(rowValue, uniqueCategoryValues):\n",
    "    return np.array(list(map(lambda x: int(x == rowValue), uniqueCategoryValues)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuousVars = [\"applicant_income_000s\", \"hud_median_family_income\", \"loan_amount_000s\",\n",
    "               \"number_of_1_to_4_family_units\", \"number_of_owner_occupied_units\", \"population\"]\n",
    "\n",
    "discreteVars = [\"agency_abbr\", \"income_bracket\", \"lien_status_name\", \"loan_purpose_name\", \n",
    "                \"loan_type_name\", \"owner_occupancy_name\", \"purchaser_type_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logisticData = df_test[[\"action_taken_name\"] + continuousVars + discreteVars].copy()\n",
    "# n0 = len(logisticData)\n",
    "# logisticData = logisticData.dropna()\n",
    "# for var in set(discreteVars) - set(['census_tract_number', 'income_bracket']):\n",
    "#     logisticData = logisticData[logisticData[var] != 'nan']\n",
    "# n1 = len(logisticData)\n",
    "# print(\"Start: %d\\tComplete: %d\\tDropped: %d (%.2f%%)\" % (n0, n1, n0 - n1, 100 * (n0 - n1) / float(n0)))\n",
    "\n",
    "# # # Z-Score Continuous Variables\n",
    "# for var in continuousVars:\n",
    "#     logisticData[[var]] = (logisticData[[var]] - logisticData[[var]].mean()) /  logisticData[[var]].std()\n",
    "    \n",
    "# # Add Dummy Variables for Discrete Variables\n",
    "# addDummiesFor = sorted(list(set(discreteVars) - set([\"census_tract_number\"])))\n",
    "# for var in addDummiesFor:\n",
    "#     sys.stdout.write(\"Starting: \"); sys.stdout.write(var); sys.stdout.write(\"\\t\")\n",
    "#     u = sorted(logisticData[var].unique())\n",
    "#     r = logisticData.apply(lambda x: oneHotFromCategory(x[var], u), axis = 1)\n",
    "#     out = np.array([i for i in r.values])\n",
    "#     logisticData = logisticData.join(pd.DataFrame(out, columns = u, index = logisticData.index))\n",
    "#     sys.stdout.write(\"Finished: \"); sys.stdout.write(var); sys.stdout.write(\"\\n\")\n",
    "\n",
    "# with open('logisticData_with_Dummies.pickle', 'wb') as f:\n",
    "#     pickle.dump(logisticData, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('logisticData_with_Dummies.pickle', 'rb') as f:\n",
    "    logisticData = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# excluding census tract data so don't do this\n",
    "# logisticData = logisticData.set_index(\"census_tract_number\")\n",
    "# logisticData[\"mean_tract_outcome\"] = logisticData.groupby(\"census_tract_number\").action_taken_name.mean()\n",
    "# logisticData = logisticData.reset_index()\n",
    "# logisticData[\"transformed_outcome\"] = logisticData.action_taken_name - logisticData.mean_tract_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticData = logisticData.rename({\n",
    "    1.0 : \"IncomeLevel_1\",\n",
    "    2.0 : \"IncomeLevel_2\",\n",
    "    3.0 : \"IncomeLevel_3\",\n",
    "    4.0 : \"IncomeLevel_4\",\n",
    "    5.0 : \"IncomeLevel_5\",\n",
    "    6.0 : \"IncomeLevel_6\",\n",
    "    7.0 : \"IncomeLevel_7\",\n",
    "    \"Not secured by a lien\" : \"LienUnsecured\",\n",
    "    \"Secured by a first lien\" : \"FirstLienSecured\",\n",
    "    \"Secured by a subordinate lien\" : \"SubordinateLienSecured\",\n",
    "    \"Home improvement\" : \"HomeImprovement\",\n",
    "    \"Home purchase\" : \"HomePurchase\",\n",
    "    \"FHA-insured\" : \"FHA_insured\",\n",
    "    \"FSA/RHS-guaranteed\" : \"FSA_RHS_guaranteed\",\n",
    "    'VA-guaranteed' : 'VA_guaranteed',\n",
    "    'Not owner-occupied as a principal dwelling' : \"NotOwnerOccupied\",\n",
    "    'Owner-occupied as a principal dwelling' : \"OwnerOccupied\",\n",
    "    'Affiliate institution' : \"AffiliateInstitution\",\n",
    "    'Commercial bank, savings bank or savings association' : \"CommercialBank\",\n",
    "    'Fannie Mae (FNMA)' : \"FannieMae\",\n",
    "    'Farmer Mac (FAMC)' : \"FarmerMac\",\n",
    "    'Freddie Mac (FHLMC)' : \"FreddieMac\",\n",
    "    'Ginnie Mae (GNMA)' : \"GinnieMae\",\n",
    "    'Life insurance company, credit union, mortgage bank, or finance company' : \"LifeInsurance\",\n",
    "    'Loan was not originated or was not sold in calendar year covered by register' : \"WrongYear\",\n",
    "    'Other type of purchaser' : \"OtherPurchaser\",\n",
    "    'Private securitization' : \"PrivateSecuritization\"\n",
    "}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4321)\n",
    "trainData, testData = train_test_split(logisticData, test_size=0.2)\n",
    "\n",
    "X_train = trainData.drop(discreteVars + [\"action_taken_name\"] , axis = 1)\n",
    "y_train_binary = trainData.action_taken_name # does not account for census_tract effects\n",
    "# y_train_cts = trainData.transformed_outcome\n",
    "\n",
    "X_test = testData.drop(discreteVars + [\"action_taken_name\"] , axis = 1)\n",
    "y_test_binary = testData.action_taken_name # does not account for census_tract effects\n",
    "# y_test_cts = testData.transformed_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_model = Logit(solver = \"lbfgs\", max_iter = 1000)\n",
    "binary_model.fit(X_train.values, y_train_binary.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_predictions = binary_model.predict(X_test.values)\n",
    "\n",
    "sum(list(map(lambda x: int(x), (logit_predictions == y_test_binary)))) / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(x):\n",
    "    return x != x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "originalWithProbs = df_test\\\n",
    ".join(pd.DataFrame(binary_model.predict_proba(X_test)[:,1], \n",
    "                   columns = [\"probOfAcceptance\"], index = X_test.index))\n",
    "originalWithProbs = originalWithProbs[~isNaN(originalWithProbs.probOfAcceptance)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see if our classifier is biased against certain races, we will group the predictions for each racial group into 10 groups [0,0.1], ... [0.9,1.0] and then see if for each group, the true probability of receiving a loan varied by race. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raceAndProbData = originalWithProbs[originalWithProbs.applicant_race_name_1.isin([Race.Asian, Race.Black, Race.White])]\\\n",
    "                  [[\"applicant_race_name_1\", \"probOfAcceptance\", \"action_taken_name\"]]\\\n",
    "                  .sort_values([\"probOfAcceptance\"], ascending = False)\n",
    "\n",
    "raceAndProbData[\"probBucket\"] = raceAndProbData.probOfAcceptance.apply(lambda x: round((x + 0.0499999999) * 10))\n",
    "means = raceAndProbData\\\n",
    ".groupby([\"applicant_race_name_1\", \"probBucket\"])\\\n",
    ".action_taken_name\\\n",
    ".mean()\\\n",
    ".reset_index(name = \"meanAcceptance\")\\\n",
    ".set_index([\"applicant_race_name_1\", \"probBucket\"])\n",
    "\n",
    "raceAndProbData = raceAndProbData.set_index([\"applicant_race_name_1\", \"probBucket\"])\n",
    "raceAndProbData[\"meanAcceptance\"] = means.meanAcceptance\n",
    "raceAndProbData = raceAndProbData.reset_index()\n",
    "\n",
    "raceAndProbData[\"predictedOutcome\"] = raceAndProbData.probOfAcceptance.apply(lambda x: int(x >= 0.5))\n",
    "\n",
    "del(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "asianData = raceAndProbData[raceAndProbData.applicant_race_name_1 == Race.Asian][[\"probBucket\", \"meanAcceptance\"]].drop_duplicates().reset_index()\n",
    "blackData = raceAndProbData[raceAndProbData.applicant_race_name_1 == Race.Black][[\"probBucket\", \"meanAcceptance\"]].drop_duplicates().reset_index()\n",
    "whiteData = raceAndProbData[raceAndProbData.applicant_race_name_1 == Race.White][[\"probBucket\", \"meanAcceptance\"]].drop_duplicates().reset_index()\n",
    "\n",
    "plt.scatter(asianData.probBucket, asianData.meanAcceptance, label = \"Asian\", color = 'g')\n",
    "plt.scatter(blackData.probBucket, blackData.meanAcceptance, label = \"Black\", color = 'k')\n",
    "plt.scatter(whiteData.probBucket, whiteData.meanAcceptance, label = \"White\", color = 'b')\n",
    "\n",
    "plt.xlabel(\"Predicted Probability of Acceptance\")\n",
    "plt.ylabel(\"True Probability of Acceptance\")\n",
    "plt.xticks(range(1,11))\n",
    "ax.legend(['Asian', 'Black or African American', 'White'], bbox_to_anchor=(1.1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plt.scatter(asianData.probBucket, asianData.meanAcceptance - whiteData.meanAcceptance, label = \"Asian\", color = 'g')\n",
    "plt.scatter(blackData.probBucket, blackData.meanAcceptance - whiteData.meanAcceptance, label = \"Black\", color = 'k')\n",
    "\n",
    "plt.xlabel(\"Predicted Probability of Acceptance\")\n",
    "plt.ylabel(\"Difference in Acceptance Rel. TO Whites\")\n",
    "ax.legend(['Asian', 'Black or African American'], bbox_to_anchor=(1.1, 1.0))\n",
    "plt.title(\"True Acceptance Probability Relative to Whites\")\n",
    "ax.axhline(y = 0, color = 'r')\n",
    "plt.xticks(range(1,11))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatrix(racesToInclude = list(raceAndProbData.applicant_race_name_1.unique())):\n",
    "    actual_pos = (raceAndProbData.action_taken_name == 1.0); actual_neg = (raceAndProbData.action_taken_name == 0.0);\n",
    "    pred_pos = (raceAndProbData.predictedOutcome == 1.0); pred_neg = (raceAndProbData.predictedOutcome == 0.0);\n",
    "    \n",
    "    racialFilter = raceAndProbData.applicant_race_name_1.isin(racesToInclude)\n",
    "\n",
    "    true_positives = len(raceAndProbData[actual_pos & pred_pos & racialFilter])\n",
    "    true_negatives = len(raceAndProbData[actual_neg & pred_neg & racialFilter])\n",
    "    false_positives = len(raceAndProbData[actual_neg & pred_pos & racialFilter])\n",
    "    false_negatives = len(raceAndProbData[actual_pos & pred_neg & racialFilter])\n",
    "\n",
    "    TPR = true_positives / (true_positives + false_negatives)\n",
    "    FPR = false_positives / (true_negatives + false_positives) # 1 - TNR\n",
    "    TNR = true_negatives / (true_negatives + false_positives)\n",
    "    FNR = false_negatives / (true_positives + false_negatives) # 1 - TPR\n",
    "\n",
    "    print(\"\"\"\n",
    "            Act.Pos | Act.Neg \n",
    "          #-------------------#\n",
    "          |         |         |\n",
    "    Pred. |  (TPR)  |  (FPR)  |\n",
    "    Pos   |  %0.3f  |  %0.3f  | \n",
    "          |         |         |\n",
    "    ------|---------#---------|\n",
    "          |         |         |\n",
    "    Pred. |  (FNR)  |  (TNR)  |\n",
    "    Neg   |  %0.3f  |  %0.3f  |\n",
    "          |         |         |\n",
    "          #-------------------#\n",
    "    \"\"\" % (TPR, FPR, FNR, TNR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getConfusionMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getConfusionMatrix([Race.Asian])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getConfusionMatrix([Race.Black])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getConfusionMatrix([Race.White])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Our classifier treats Whites and Asians virtually identically from a confusion matrix perspective. However, our classifier is less likely to \"mistakenly\" approve a black applicant for a loan (the False Positive Rate for Blacks is 18%, compared to 33% for whites ) and more likely to \"mistakenly\" reject a black applicant for a loan (the False Negative Rate for Blacks is 11%, compared to 8% for Whites). These discrepancies are most prevalent in the ~50% porbabiltiy of loan origination/purchased by an institution range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
